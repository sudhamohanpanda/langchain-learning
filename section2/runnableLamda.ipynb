{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0e7afd",
   "metadata": {},
   "source": [
    "- Shenario: Will ask a question to llm1. if respnose length is greter then 300 we will summerize the contain using llm2 otherwise will run in llm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b06b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://api.smith.langchain.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')\n",
    "\n",
    "# Debug: Print to verify values are loaded\n",
    "print(f\"Endpoint: {os.getenv('LANGSMITH_ENDPOINT')}\")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm1 = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen2.5:latest\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "llm2 = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"mistral:latest\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "llm3 = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"DeepSeek-R1\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec38c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:The sky appears blue during the day due to a phenomenon called Rayleigh scattering. Here's a more detailed explanation:\n",
      "\n",
      "1. **Sunlight Composition**: Sunlight contains all colors of the visible spectrumâ€”red, orange, yellow, green, blue, indigo, and violet. When sunlight enters Earth's atmosphere, it interacts with molecules and small particles in the air.\n",
      "\n",
      "2. **Scattering by Molecules**: The shorter, bluer wavelengths of light are scattered more easily by the gases and tiny particles (such as nitrogen and oxygen) in the atmosphere. This process is known as Rayleigh scattering.\n",
      "\n",
      "3. **Blue Light Dominance**: Because blue light is scattered more than other colors, it becomes predominant in the sky when we look up at it during the day.\n",
      "\n",
      "4. **Color Perception**: When you look at the sky directly, your eyes receive a mixture of these scattered blue wavelengths. Since your eye has a higher sensitivity to blue light and the sky doesn't have any other color to contrast with (like it does near the horizon), the sky appears blue.\n",
      "\n",
      "5. **Other Colors in Sky**: During sunrise or sunset, you might see orange, pink, or red colors because the sun is lower in the sky, and its light travels a longer path through the atmosphere. This additional scattering of shorter wavelengths results in more prominent reds and oranges.\n",
      "\n",
      "In summary, the blue color of the sky during the day is due to the way our atmosphere scatters sunlight, with shorter blue wavelengths being scattered more than others.\n",
      "Answer: The blue appearance of the sky during the day is primarily due to Rayleigh scattering, where shorter blue wavelengths are scattered more by Earth's atmosphere, making blue light predominant when looking up.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "prompt_template1 = ChatPromptTemplate([\n",
    "    (\"system\",\"You are an LLM expert\"),\n",
    "    (\"user\",\"Why sky is blue?\")])\n",
    "\n",
    "chain1 = prompt_template1 | llm1 | StrOutputParser()\n",
    "response = chain1.invoke({}) \n",
    "print(\"Response:\"+response)\n",
    "\n",
    "def choose_llm(response): \n",
    "    response_text = str(response)\n",
    "    if len(response_text) > 100:\n",
    "        return llm2\n",
    "    else:\n",
    "        return llm1\n",
    "\n",
    "llm_selector = RunnableLambda(choose_llm)\n",
    "\n",
    "prompt_template2 = ChatPromptTemplate([\n",
    "    (\"system\",\"You are an LLM expert\"),\n",
    "    (\"user\",\"summerise {response} in one line.\")])\n",
    "\n",
    "chain2 = prompt_template2 | llm_selector | StrOutputParser()\n",
    "answer = chain2.invoke({\"response\": response})\n",
    "print(\"Answer:\"+answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
