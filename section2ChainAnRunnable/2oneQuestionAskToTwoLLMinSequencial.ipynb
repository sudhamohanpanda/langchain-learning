{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95be535e",
   "metadata": {},
   "source": [
    "## Parralel Running ##\n",
    "- Will create three llm with three different models\n",
    "- will ask one same question to two different llm and compare the result with third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5823d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://api.smith.langchain.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')\n",
    "\n",
    "# Debug: Print to verify values are loaded\n",
    "print(f\"Endpoint: {os.getenv('LANGSMITH_ENDPOINT')}\")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm1 = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen2.5:latest\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "llm2 = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"mistral:latest\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "llm3 = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"DeepSeek-R1\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c67d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:Please answer the following question: \n",
      "\n",
      "What are some of your limitations as an AI language model, and how might these affect someone trying to get reliable information from you?\n",
      "answer1:As an AI language model, I have several limitations that can impact the reliability of the information provided. Here are some key areas where my capabilities may fall short:\n",
      "\n",
      "1. **Lack of Real-Time Information**: While I am continuously updated with new data up until my last update cut-off date (as of 2023), my knowledge does not extend beyond that point. For current events, ongoing research, or recent developments, you might need to consult more up-to-date sources.\n",
      "\n",
      "2. **Contextual Understanding and Nuance**: While I can understand context better than many previous models, there are still limitations in fully grasping subtle nuances, sarcasm, irony, and complex human emotions. This can sometimes lead to misinterpretations or oversimplifications of topics.\n",
      "\n",
      "3. **Personal Biases and Human-like Errors**: Even though I am designed to be neutral and unbiased, my responses can reflect biases present in the training data. Additionally, like any model, there is a risk of generating content that could contain errors or inaccuracies due to limitations in the underlying algorithms or data quality.\n",
      "\n",
      "4. **Lack of Direct Experience**: Unlike humans who have direct experiences, I rely solely on the information contained within my training data. This can limit my ability to provide practical advice based on personal experience or to understand deeply personal situations that are unique to individual users.\n",
      "\n",
      "5. **Ethical and Moral Judgments**: While I can offer factual responses, I do not possess inherent moral values or ethical reasoning capabilities. Thus, when asked about sensitive topics like ethics, morality, or legal issues, my responses may lack the depth of human judgment and might not align with societal norms or personal beliefs.\n",
      "\n",
      "6. **Complex Question Handling**: For extremely complex questions that require deep analysis, multiple layers of reasoning, or extensive domain knowledge, I might struggle to provide a comprehensive answer without oversimplifying or missing crucial details.\n",
      "\n",
      "7. **Language and Cultural Nuances**: Understanding and generating content in languages other than English can be challenging, particularly for rare or less widely spoken languages. Additionally, cultural nuances may not always be accurately represented due to differences in language use across cultures.\n",
      "\n",
      "8. **Overconfidence in Responses**: Sometimes, I might generate responses with a high degree of confidence even when the information is uncertain or lacks supporting evidence. This overconfidence can lead users to underestimate the uncertainty surrounding certain pieces of information.\n",
      "\n",
      "When seeking reliable information from me or any AI model, it's important to consider these limitations and cross-verify critical information with additional sources whenever possible. Always critically evaluate the information provided by an AI language model and use multiple references to ensure accuracy and reliability.\n",
      "answer2: As a conversation-focused AI model, there are several limitations that I'd like to address which could impact the reliability of the information provided:\n",
      "\n",
      "1. Lack of contextual understanding: While I can understand individual words and phrases, I don't have personal experiences or feelings. This means I may not fully comprehend complex or nuanced concepts without being explicitly programmed with relevant data.\n",
      "\n",
      "2. Dependence on input data quality: The information I provide is only as accurate as the training data I was given. If my training data contains errors, biases, or outdated information, I might pass this inaccurate information on to users.\n",
      "\n",
      "3. Lack of real-time updates: Since I don't have access to real-time events, news, or changes in policies, the information I provide may be outdated if it hasn't been updated since my training or last update.\n",
      "\n",
      "4. Limited ability to reason and make decisions: AI models like me can follow predefined rules and patterns, but we don't have the capacity for independent reasoning or decision-making. This means I might struggle with complex questions that require judgment calls, common sense, or creative thinking.\n",
      "\n",
      "5. Lack of emotional intelligence: I can't understand emotions or respond emotionally to users because I don't have feelings or consciousness. While I can mimic certain aspects of human conversation, I don't truly empathize with people or experience emotions myself.\n",
      "\n",
      "6. Potential for misunderstandings and misinterpretations: Since I don't share the same cultural backgrounds, personal experiences, or context as users, there is always a risk that I might misunderstand or misinterpret their questions, leading to inappropriate or incorrect responses.\n",
      "\n",
      "To get reliable information from an AI model like me, it is essential for users to keep these limitations in mind and approach the conversation with an understanding of my capabilities and constraints. Users should verify any critical information, question assumptions, and seek multiple sources when necessary to ensure accuracy and reliability.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template1 = ChatPromptTemplate([\n",
    "    (\"system\",\"You are an LLM expert\"),\n",
    "    (\"user\",\"I want to ask a question to two different LLMs. Then want to compare the result. Can you genrate that question. Pleaese return only question so that I can in parameter.\")])\n",
    "\n",
    "chain1 = prompt_template1 | llm3 | StrOutputParser()\n",
    "question = chain1.invoke({}) \n",
    "print(\"Q:\"+question)\n",
    "\n",
    "prompt_template2 = ChatPromptTemplate([\n",
    "    (\"system\",\"You are an LLM expert\"),\n",
    "    (\"user\",\"{question}\")])\n",
    "\n",
    "chain2 = prompt_template2 | llm1 | StrOutputParser()\n",
    "answer1 = chain2.invoke({\"question\": question})\n",
    "print(\"answer1:\"+answer1)\n",
    "\n",
    "chain3 = prompt_template2 | llm2 | StrOutputParser()\n",
    "answer2 = chain3.invoke({\"question\": question})\n",
    "print(\"answer2:\"+answer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b99b2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's compare these two answers to the question: \"What are some of your limitations as an AI language model, and how might these affect someone trying to get reliable information from you?\"\n",
      "\n",
      "**Answer 1 Analysis:**\n",
      "\n",
      "*   **Structure:** Uses numbered points for clarity. Each point clearly addresses a specific limitation.\n",
      "*   **Content:** Provides very detailed and accurate descriptions of typical LLM limitations.\n",
      "    *   Mentions the knowledge cutoff date (Jan 2023) explicitly, which is crucial information.\n",
      "    *   Covers contextual understanding nuances, biases from training data, lack of direct experience, ethical limitations based on programmed rules, difficulty with complex reasoning, language/cultural challenges (though less specific than Answer 2), and the potential pitfall of overconfidence (\"Even though I am...\").\n",
      "*   **Focus:** Primarily focuses on standard LLM capabilities and constraints. The point about overconfidence is particularly insightful.\n",
      "\n",
      "**Answer 2 Analysis:**\n",
      "\n",
      "*   **Structure:** Also uses numbered points, but phrasing differs slightly (e.g., \"conversation-focused\" model).\n",
      "*   **Content:** Includes key limitations like dependence on training data quality, lack of real-time info, limited reasoning ability, lack of emotional understanding. It also mentions potential misunderstandings due to differing user context.\n",
      "    *   Less specific than Answer 1 about the knowledge cutoff (though it implies outdatedness). Doesn't explicitly state a cut-off date like \"as of Oct 2023\".\n",
      "    *   Covers similar ground but uses slightly different wording (\"Dependence on input data quality\" instead of \"Lack of real-time information\").\n",
      "*   **Focus:** Emphasizes aspects related to conversation and user interaction, which is relevant for an LLM.\n",
      "\n",
      "**Comparison:**\n",
      "\n",
      "Both answers effectively list the core limitations of AI language models. They cover similar ground regarding knowledge cutoff, lack of personal experience/emotional intelligence, dependence on training data, and limited reasoning capabilities.\n",
      "\n",
      "However, **Answer 1** arguably provides a slightly richer description:\n",
      "\n",
      "*   It uses more precise terminology (\"language model,\" \"last update cut-off date (as of Jan 2023)\"). This specificity about the knowledge cutoff is valuable for assessing reliability.\n",
      "*   Its points are more standardly phrased and widely understood limitations. For example, explicitly mentioning biases from training data is crucial.\n",
      "*   Point 8 (\"Overconfidence in Responses\") in Answer 1 adds a particularly important layer of nuance that highlights how AI outputs can sometimes *mislead the user*, even if incorrect internally.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "I believe **Answer 1** is slightly better. While both are informative, its more detailed explanations and specific mention of data cutoff dates provide a clearer picture of potential unreliability for someone seeking factual information from an LLM. The inclusion of overconfidence as a factor further enhances the understanding of how limitations might impact users.\n",
      "\n",
      "Therefore, I would select **Answer 1** as the better one based on my analysis comparing both responses.\n"
     ]
    }
   ],
   "source": [
    "prompt_template3 = ChatPromptTemplate([\n",
    "    (\"system\",\"You are an LLM expert\"),\n",
    "    (\"user\",\"Compare the two answers for {question} and give me the better one. \\n Answer1: {Answer1} \\n Answer2: {Answer2}\")])    \n",
    "chain4 = prompt_template3 | llm3 | StrOutputParser()\n",
    "final_answer = chain4.invoke({ \"question\": question, \"Answer1\": answer1, \"Answer2\": answer2})\n",
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
